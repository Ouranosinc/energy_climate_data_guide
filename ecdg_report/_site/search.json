[
  {
    "objectID": "datasets/precipitation/Precipitation_Datasets.html",
    "href": "datasets/precipitation/Precipitation_Datasets.html",
    "title": "Precipitation Datasets",
    "section": "",
    "text": "Here we present the datasets for precipitation.",
    "crumbs": [
      "Climate Datasets",
      "Precipitation"
    ]
  },
  {
    "objectID": "datasets/temperature/Temperature_Datasets.html",
    "href": "datasets/temperature/Temperature_Datasets.html",
    "title": "Climate Data for the Electricity Sector",
    "section": "",
    "text": "Temperature datasets are crucial for understanding climate variability and change. These datasets come from a variety of sources, each offering unique strengths depending on the type of analysis required.\nThe datasets discussed here can be grouped into the following categories:\nObservational data are direct temperature measurements from weather stations, buoys, and satellites. These provide the most accurate and high-resolution temperature records, but their coverage is often limited to specific locations, leading to gaps in certain regions, particularly oceans and remote areas.\nGridded observational datasets address this limitation by interpolating station data across a defined grid, providing more comprehensive spatial coverage. These datasets, such as those produced by national meteorological agencies, offer a balance between accuracy and spatial representation, though uncertainties arise in data-sparse regions.\nReanalysis datasets combine historical observations with climate models to create consistent, long-term reconstructions of the atmosphere. They offer global coverage and high temporal resolution, making them valuable for analyzing past climate conditions and trends. However, reanalysis products rely on model-based data assimilation, which may introduce biases, especially in areas with limited observations.\nClimate model data, often from global climate models (GCMs), simulate temperature under different greenhouse gas scenarios. These projections are essential for understanding future climate patterns and assessing potential impacts. While models provide large-scale temperature trends, they lack the precision of observational data due to their coarse spatial resolution and inherent uncertainties in modeling processes.\nTogether, these temperature datasets enable a comprehensive view of both historical and future climate conditions, supporting a wide range of climate research and impact assessments.\nThe following table shows temperarture datatsets relevant to the energy sector.\n\n\n\n\n\nTemperature Datasets\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nsource\ndata type\nspatial domain\nspatial resolution\ntemporal coverage\ntime step\ndata format\n\n\n\n\n\nMSC Observations\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable (1940- present)\nHourly; Daily; Monthly\nCSV; GeoJSON\ndetails\n\n\nMSC Climate Normals\nMSC/ECCC\nStation data\nCanada\nPoint data\n1941-1970; 1951-1980; 1961-1990; 1971-2000; 1981-2010.\nClimatological means\nCSV; GeoJSON\ndetails\n\n\nMSC Daily Climate Records (LTCE, Long Term Climate Extremes)\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable\nRecords for each day of the year\nCSV; GeoJSON\ndetails\n\n\nAHCCD\nCRD/ECCC\nStation data\nCanada\nPoint data\nVariable (1950 to present)\nDaily; Monthly; Seasonal; Annual\nASCII; CSV; GeoJSON\ndetails\n\n\nHydro-Québec Station data\nHydro-Québec\nStation data\nNorthern Québec at hydroelectric stations\nPoint Data\nVariable (1990 to present)\nVariable ( sub-daily to daily)\nNone\ndetails\n\n\nWhite Pass Railway & River Divisions dataset, Yukon\nYukon Research Centre\nStation data from archives\nThe upper Yukon River basin\nPoint data\n1902-1957\nDaily\nExcel files\ndetails\n\n\nSCDNA\nUniversity of Saskatchewan\nStation data and reanalyses blend\nNorth America\nPoint data\n1979-2018\nDaily\nNetCDF\ndetails\n\n\nCANGRD\nCRD/ECCC\nGridded observations\nCanada\n50 km x 50 km\n1948-2017 (anomalies)\nMonthly; Seasonal; Annual\nCSV; GeoJSON\ndetails\n\n\nANUSPLIN\nCFS/NRCan\nGridded observations\nCanada and North America\n(10 km x 10 km) and (2 km x 2 km)\n1950-2017\nDaily; Pentad; Monthly; Climatological means\nASCII; NetCDF\ndetails\n\n\nCRU TS Version 4\nCRU/University of East Anglia\nGridded observations\nGlobal (land only)\n0.5° x 0.5°\n1901–2018\nMonthly\nNetCDF\ndetails\n\n\nWorldClim2\nWorld Conservation Monitoring Centre/UNEP\nGridded observations\nGlobal (land only)\n10 arc minutes (~340 km);5 arc minutes;2.5 arc minutes; 30 arc seconds (1 km)\n1970-2000\nMonthly\nGeoTIFF\ndetails\n\n\nDaymet Version 4\nEnvironmental Sciences Division/Oak Ridge National Laboratory\nGridded observations\nNorth America (land only)\n1 km x 1 km\n1980-2019\nDaily\nNetCDF\ndetails\n\n\nPNWNAMET\nPCIC\nGridded observations\nNorth-western North America\n3.75 arc minutes (~6 km)\n1945-2012\nDaily\nASCII; NetCDF\ndetails\n\n\nMet1km\nNRCan\nBlend of gridded products\nCanada\n1 km x 1 km\n1901–2017\nDaily\nNone\ndetails\n\n\nERA5\nECMWF\nGlobal atmospheric reanalysis\nGlobal\n0.25° x 0.25°\n1950 to present\nHourly; Daily; Monthly\nGRIB;NetCDF\ndetails\n\n\nCFSR\nNCEP\nGlobal atmospheric reanalysis\nGlobal\n0.5° x 0.5°\n1979-2017\nSub-daily; Monthly\nGRIB\ndetails\n\n\nMERRA-2\nNASA\nGlobal atmospheric reanalysis\nGlobal\n½° latitude x ⅝° longitude\n1980 to present\nHourly; Daily; Monthly\nNetCDF\ndetails\n\n\nJRA-55\nJMA\nGlobal atmospheric reanalysis\nGlobal\n0.6258ᵒ x 0.6258ᵒ\n1957-2021\n3h; 6h; Daily; Monthly\nNetCDF\ndetails\n\n\nASRv2\nByrd Polar Research Center/The Ohio State University; UCAR/NCAR\nRegional reanalysis\nArctic\n15 km x 15 km\n2000-2016\n3h; Monthly\nNetCDF\ndetails\n\n\nNARR\nNCEP\nRegional reanalysis\nNorth America\n32 km x 32 km\n1979-2021\nSub-daily; Monthly\nGRIB\ndetails\n\n\nRDRSv2\nCCMEP/ECCC\nRegional reanalysis\nNorth America\n10 km x 10 km\n2000-2017(1980-1999 pending)\nHourly\nRPN\ndetails\n\n\n20CRv3\nCIRES; NOAA; DOE\nGlobal atmospheric reanalysis\nGlobal\nT254 (approximately 75 km at the equator)\n20CRv3.SI is available for years 1836-1980 and 20CRv3.MO is available for years 1981-2015\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nERA5-Land\nECMWF\nLand surface reanalysis/model\nGlobal (land only)\n0.1° x 0.1° (9 km)\n1950 to present\nHourly; Monthly\nGRIB; NetCDF\ndetails\n\n\nAgERA\nECMWF\nRe-gridded reanalysis\nGlobal (land only)\n0.1° x 0.1°\n1979 to present\nDaily\nNetCDF\ndetails\n\n\nAgCFSR\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nAgMERRA\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nGMFD\nPrinceton University\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1948-2016\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nCRU JRA\nCRU/University of East Anglia\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.5° × 0.5°\n1901-2018\n6h\nNetCDF\ndetails\n\n\nS14FD\nDIAS\nRe-gridded reanalysis with corrections\nGlobal\n0.5° x 0.5°\n1958-2013\nDaily\nNetCDF\ndetails",
    "crumbs": [
      "Climate Datasets",
      "Temperature"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_managment.html",
    "href": "sectors/enterprise_risk_managment.html",
    "title": "Enterprise Risk Management",
    "section": "",
    "text": "Maybe consider this!\n\n\n\nThe following may need to become distinct sections!",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_managment.html#infrastructure-condition-assessment",
    "href": "sectors/enterprise_risk_managment.html#infrastructure-condition-assessment",
    "title": "Enterprise Risk Management",
    "section": "Infrastructure Condition Assessment",
    "text": "Infrastructure Condition Assessment",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_managment.html#investment-prioritization",
    "href": "sectors/enterprise_risk_managment.html#investment-prioritization",
    "title": "Enterprise Risk Management",
    "section": "Investment Prioritization",
    "text": "Investment Prioritization",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_managment.html#vegetation-management",
    "href": "sectors/enterprise_risk_managment.html#vegetation-management",
    "title": "Enterprise Risk Management",
    "section": "Vegetation Management",
    "text": "Vegetation Management",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/nuclear_safety_review.html",
    "href": "sectors/nuclear_safety_review.html",
    "title": "Nuclear Safety Reviews",
    "section": "",
    "text": "First\n\n\nSecond\n\n\nThird",
    "crumbs": [
      "Electricity Sector Activities",
      "Nuclear Safety Reviews"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Climate Data for the Electriciy Sector",
    "section": "",
    "text": "Built with Quarto\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "This is the amazing introduction to our report on everything ‘climate data’ regarding their use in the electricity sector.\nIt goes like this:\n\n\n\n\n\nflowchart LR\n  A[What data are out there] --&gt; B(An Inventory)\n  B --&gt; C{Interviewswith\\nEnergy Sector\\nChampions}\n  C --&gt; D[Best practices]\n  C --&gt; E[Gap analysis]",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "datasets/temperature/RDRS.html",
    "href": "datasets/temperature/RDRS.html",
    "title": "Regional Deterministic Reforecast System - RDRS v2.1",
    "section": "",
    "text": "Overview\nEnvironment and Climate Change Canada has initiated the production of a 1980–2018, 10 km, North American precipitation and surface reanalysis. ERA-Interim is used to initialize the Global Deterministic Reforecast System (GDRS) at a 39 km resolution. Its output is then dynamically downscaled to 10 km by the Regional Deterministic Reforecast System (RDRS). Coupled with the RDRS, the Canadian Land Data Assimilation System (CaLDAS) and Precipitation Analysis (CaPA) are used to produce surface and precipitation analyses. All systems used are close to operational model versions and configurations.\nGasset, et al. (2021)\n\n\nTemperature Data\nRDRS v2.1 provides daily and hourly temperature data from 1980 onward, lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nsource\ndata type\nspatial domain\nspatial resolution\ntemporal coverage\ntime step\ndata format\n\n\n\n\n\nRDRSv2\nCCMEP/ECCC\nRegional reanalysis\nNorth America\n10 km x 10 km\n2000-2017(1980-1999 pending)\nHourly\nRPN\ndetails",
    "crumbs": [
      "Climate Datasets",
      "Temperature",
      "Regional Deterministic Reforecast System - RDRS v2.1"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html#nuclear",
    "href": "sectors/demand_forecasting.html#nuclear",
    "title": "Demand Forecasting",
    "section": "Nuclear",
    "text": "Nuclear\nlorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html#solar",
    "href": "sectors/demand_forecasting.html#solar",
    "title": "Demand Forecasting",
    "section": "Solar",
    "text": "Solar\nlorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html#thermal",
    "href": "sectors/demand_forecasting.html#thermal",
    "title": "Demand Forecasting",
    "section": "Thermal",
    "text": "Thermal\nlorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html#wind",
    "href": "sectors/demand_forecasting.html#wind",
    "title": "Demand Forecasting",
    "section": "Wind",
    "text": "Wind\nlorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html",
    "href": "sectors/demand_forecasting.html",
    "title": "Demand Forecasting",
    "section": "",
    "text": "lorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/demand_forecasting.html#hydro",
    "href": "sectors/demand_forecasting.html#hydro",
    "title": "Demand Forecasting",
    "section": "",
    "text": "lorem ipsum, bla, bla, and blah",
    "crumbs": [
      "Electricity Sector Activities",
      "Demand Forecasting"
    ]
  },
  {
    "objectID": "sectors/electricity_sector_activities.html#overview-of-activities",
    "href": "sectors/electricity_sector_activities.html#overview-of-activities",
    "title": "Electricity Sector Activities",
    "section": "Overview of Activities",
    "text": "Overview of Activities",
    "crumbs": [
      "Electricity Sector Activities"
    ]
  },
  {
    "objectID": "sectors/infrastructure_design.html#thermal-nuclear",
    "href": "sectors/infrastructure_design.html#thermal-nuclear",
    "title": "Resource Adequacy Planning Infrastructure Design",
    "section": "Thermal & Nuclear",
    "text": "Thermal & Nuclear",
    "crumbs": [
      "Electricity Sector Activities",
      "Resource Adequacy Planning Infrastructure Design"
    ]
  },
  {
    "objectID": "sectors/infrastructure_design.html#transmission-distribution",
    "href": "sectors/infrastructure_design.html#transmission-distribution",
    "title": "Resource Adequacy Planning Infrastructure Design",
    "section": "Transmission & Distribution",
    "text": "Transmission & Distribution",
    "crumbs": [
      "Electricity Sector Activities",
      "Resource Adequacy Planning Infrastructure Design"
    ]
  },
  {
    "objectID": "sectors/forest_fire_monitoring_and_awareness.html",
    "href": "sectors/forest_fire_monitoring_and_awareness.html",
    "title": "Forest Fire Monitoring and Awareness",
    "section": "",
    "text": "This section is about forest fires and how to manage awareness about this threat.",
    "crumbs": [
      "Electricity Sector Activities",
      "Forest Fire Monitoring and Awareness"
    ]
  },
  {
    "objectID": "sectors/forest_fire_monitoring_and_awareness.html#this-is-a-test",
    "href": "sectors/forest_fire_monitoring_and_awareness.html#this-is-a-test",
    "title": "Forest Fire Monitoring and Awareness",
    "section": "This is a test:",
    "text": "This is a test:\nI want to see if I can smoothly type into the Notebook file locally in my PyCharm IDE and everything will update nicely remotely in jupyter lab and quarto output.\nSo while I type this in PyCharm, I have my jupyter server running on doris.ouranos.ca and jupyter lab is open in my browser.\nIf I save this file locally, it should be ssh-ed to my directory on doris, updated in jupyter lab in my browser and subsequently Quarto should update the output which is open in my browser as well, that is, the quarto server is listening to my notebooks and quarto files.\nI will now also go ahead and make some changes in the _quarto.yml file.\n\nHere is just a Third Level Heading\nSo this would be the corresponding text.\n\nAnd just for the heck of it, here is also a Fourth Level Heading\nLet’s see if this is also rendered in the TOC, indicating what’s “On this page”.",
    "crumbs": [
      "Electricity Sector Activities",
      "Forest Fire Monitoring and Awareness"
    ]
  },
  {
    "objectID": "sectors/forest_fire_monitoring_and_awareness.html#result-of-the-test",
    "href": "sectors/forest_fire_monitoring_and_awareness.html#result-of-the-test",
    "title": "Forest Fire Monitoring and Awareness",
    "section": "Result of the test:",
    "text": "Result of the test:\nIt very nicely does all that but at first I was a little impatient and did some fiddling with the upload of the file for everything to show up in the browser, the jupyter lab and the quarto preview page. Then I just went on typing and next time around it just does it all and everything show up alright. It’s magical, hihi!\n\nVery cool!",
    "crumbs": [
      "Electricity Sector Activities",
      "Forest Fire Monitoring and Awareness"
    ]
  },
  {
    "objectID": "datasets/temperature/Temperature_Datasets.html#temperature-datasets-1",
    "href": "datasets/temperature/Temperature_Datasets.html#temperature-datasets-1",
    "title": "Temperature Datasets",
    "section": "",
    "text": "Temperature datasets are crucial for understanding climate variability and change. These datasets come from a variety of sources, each offering unique strengths depending on the type of analysis required.\nObservational data are direct temperature measurements from weather stations, buoys, and satellites. These provide the most accurate and high-resolution temperature records, but their coverage is often limited to specific locations, leading to gaps in certain regions, particularly oceans and remote areas.\nGridded observational datasets address this limitation by interpolating station data across a defined grid, providing more comprehensive spatial coverage. These datasets, such as those produced by national meteorological agencies, offer a balance between accuracy and spatial representation, though uncertainties arise in data-sparse regions.\nReanalysis datasets combine historical observations with climate models to create consistent, long-term reconstructions of the atmosphere. They offer global coverage and high temporal resolution, making them valuable for analyzing past climate conditions and trends. However, reanalysis products rely on model-based data assimilation, which may introduce biases, especially in areas with limited observations.\nClimate model data, often from global climate models (GCMs), simulate temperature under different greenhouse gas scenarios. These projections are essential for understanding future climate patterns and assessing potential impacts. While models provide large-scale temperature trends, they lack the precision of observational data due to their coarse spatial resolution and inherent uncertainties in modeling processes.\nTogether, these temperature datasets enable a comprehensive view of both historical and future climate conditions, supporting a wide range of climate research and impact assessments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nsource\ndata type\nspatial domain\nspatial resolution\ntemporal coverage\ntime step\ndata format\n\n\n\n\n\nMSC Observations\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable (1940- present)\nHourly; Daily; Monthly\nCSV; GeoJSON\ndetails\n\n\nMSC Climate Normals\nMSC/ECCC\nStation data\nCanada\nPoint data\n1941-1970; 1951-1980; 1961-1990; 1971-2000; 1981-2010.\nClimatological means\nCSV; GeoJSON\ndetails\n\n\nMSC Daily Climate Records (LTCE, Long Term Climate Extremes)\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable\nRecords for each day of the year\nCSV; GeoJSON\ndetails\n\n\nAHCCD\nCRD/ECCC\nStation data\nCanada\nPoint data\nVariable (1950 to present)\nDaily; Monthly; Seasonal; Annual\nASCII; CSV; GeoJSON\ndetails\n\n\nHydro-Québec Station data\nHydro-Québec\nStation data\nNorthern Québec at hydroelectric stations\nPoint Data\nVariable (1990 to present)\nVariable ( sub-daily to daily)\nNone\ndetails\n\n\nWhite Pass Railway & River Divisions dataset, Yukon\nYukon Research Centre\nStation data from archives\nThe upper Yukon River basin\nPoint data\n1902-1957\nDaily\nExcel files\ndetails\n\n\nSCDNA\nUniversity of Saskatchewan\nStation data and reanalyses blend\nNorth America\nPoint data\n1979-2018\nDaily\nNetCDF\ndetails\n\n\nCANGRD\nCRD/ECCC\nGridded observations\nCanada\n50 km x 50 km\n1948-2017 (anomalies)\nMonthly; Seasonal; Annual\nCSV; GeoJSON\ndetails\n\n\nANUSPLIN\nCFS/NRCan\nGridded observations\nCanada and North America\n(10 km x 10 km) and (2 km x 2 km)\n1950-2017\nDaily; Pentad; Monthly; Climatological means\nASCII; NetCDF\ndetails\n\n\nCRU TS Version 4\nCRU/University of East Anglia\nGridded observations\nGlobal (land only)\n0.5° x 0.5°\n1901–2018\nMonthly\nNetCDF\ndetails\n\n\nWorldClim2\nWorld Conservation Monitoring Centre/UNEP\nGridded observations\nGlobal (land only)\n10 arc minutes (~340 km);5 arc minutes;2.5 arc minutes; 30 arc seconds (1 km)\n1970-2000\nMonthly\nGeoTIFF\ndetails\n\n\nDaymet Version 4\nEnvironmental Sciences Division/Oak Ridge National Laboratory\nGridded observations\nNorth America (land only)\n1 km x 1 km\n1980-2019\nDaily\nNetCDF\ndetails\n\n\nPNWNAMET\nPCIC\nGridded observations\nNorth-western North America\n3.75 arc minutes (~6 km)\n1945-2012\nDaily\nASCII; NetCDF\ndetails\n\n\nMet1km\nNRCan\nBlend of gridded products\nCanada\n1 km x 1 km\n1901–2017\nDaily\nNone\ndetails\n\n\nERA5\nECMWF\nGlobal atmospheric reanalysis\nGlobal\n0.25° x 0.25°\n1950 to present\nHourly; Daily; Monthly\nGRIB;NetCDF\ndetails\n\n\nCFSR\nNCEP\nGlobal atmospheric reanalysis\nGlobal\n0.5° x 0.5°\n1979-2017\nSub-daily; Monthly\nGRIB\ndetails\n\n\nMERRA-2\nNASA\nGlobal atmospheric reanalysis\nGlobal\n½° latitude x ⅝° longitude\n1980 to present\nHourly; Daily; Monthly\nNetCDF\ndetails\n\n\nJRA-55\nJMA\nGlobal atmospheric reanalysis\nGlobal\n0.6258ᵒ x 0.6258ᵒ\n1957-2021\n3h; 6h; Daily; Monthly\nNetCDF\ndetails\n\n\nASRv2\nByrd Polar Research Center/The Ohio State University; UCAR/NCAR\nRegional reanalysis\nArctic\n15 km x 15 km\n2000-2016\n3h; Monthly\nNetCDF\ndetails\n\n\nNARR\nNCEP\nRegional reanalysis\nNorth America\n32 km x 32 km\n1979-2021\nSub-daily; Monthly\nGRIB\ndetails\n\n\nRDRSv2\nCCMEP/ECCC\nRegional reanalysis\nNorth America\n10 km x 10 km\n2000-2017(1980-1999 pending)\nHourly\nRPN\ndetails\n\n\n20CRv3\nCIRES; NOAA; DOE\nGlobal atmospheric reanalysis\nGlobal\nT254 (approximately 75 km at the equator)\n20CRv3.SI is available for years 1836-1980 and 20CRv3.MO is available for years 1981-2015\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nERA5-Land\nECMWF\nLand surface reanalysis/model\nGlobal (land only)\n0.1° x 0.1° (9 km)\n1950 to present\nHourly; Monthly\nGRIB; NetCDF\ndetails\n\n\nAgERA\nECMWF\nRe-gridded reanalysis\nGlobal (land only)\n0.1° x 0.1°\n1979 to present\nDaily\nNetCDF\ndetails\n\n\nAgCFSR\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nAgMERRA\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nGMFD\nPrinceton University\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1948-2016\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nCRU JRA\nCRU/University of East Anglia\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.5° × 0.5°\n1901-2018\n6h\nNetCDF\ndetails\n\n\nS14FD\nDIAS\nRe-gridded reanalysis with corrections\nGlobal\n0.5° x 0.5°\n1958-2013\nDaily\nNetCDF\ndetails",
    "crumbs": [
      "Climate Datasets",
      "Temperature"
    ]
  },
  {
    "objectID": "datasets/temperature/Temperature_Datasets.html#temperature-datasets",
    "href": "datasets/temperature/Temperature_Datasets.html#temperature-datasets",
    "title": "Climate Data for the Electricity Sector",
    "section": "",
    "text": "Temperature datasets are crucial for understanding climate variability and change. These datasets come from a variety of sources, each offering unique strengths depending on the type of analysis required.\nThe datasets discussed here can be grouped into the following categories:\nObservational data are direct temperature measurements from weather stations, buoys, and satellites. These provide the most accurate and high-resolution temperature records, but their coverage is often limited to specific locations, leading to gaps in certain regions, particularly oceans and remote areas.\nGridded observational datasets address this limitation by interpolating station data across a defined grid, providing more comprehensive spatial coverage. These datasets, such as those produced by national meteorological agencies, offer a balance between accuracy and spatial representation, though uncertainties arise in data-sparse regions.\nReanalysis datasets combine historical observations with climate models to create consistent, long-term reconstructions of the atmosphere. They offer global coverage and high temporal resolution, making them valuable for analyzing past climate conditions and trends. However, reanalysis products rely on model-based data assimilation, which may introduce biases, especially in areas with limited observations.\nClimate model data, often from global climate models (GCMs), simulate temperature under different greenhouse gas scenarios. These projections are essential for understanding future climate patterns and assessing potential impacts. While models provide large-scale temperature trends, they lack the precision of observational data due to their coarse spatial resolution and inherent uncertainties in modeling processes.\nTogether, these temperature datasets enable a comprehensive view of both historical and future climate conditions, supporting a wide range of climate research and impact assessments.\nThe following table shows temperarture datatsets relevant to the energy sector.\n\n\n\n\n\nTemperature Datasets\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nsource\ndata type\nspatial domain\nspatial resolution\ntemporal coverage\ntime step\ndata format\n\n\n\n\n\nMSC Observations\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable (1940- present)\nHourly; Daily; Monthly\nCSV; GeoJSON\ndetails\n\n\nMSC Climate Normals\nMSC/ECCC\nStation data\nCanada\nPoint data\n1941-1970; 1951-1980; 1961-1990; 1971-2000; 1981-2010.\nClimatological means\nCSV; GeoJSON\ndetails\n\n\nMSC Daily Climate Records (LTCE, Long Term Climate Extremes)\nMSC/ECCC\nStation data\nCanada\nPoint data\nVariable\nRecords for each day of the year\nCSV; GeoJSON\ndetails\n\n\nAHCCD\nCRD/ECCC\nStation data\nCanada\nPoint data\nVariable (1950 to present)\nDaily; Monthly; Seasonal; Annual\nASCII; CSV; GeoJSON\ndetails\n\n\nHydro-Québec Station data\nHydro-Québec\nStation data\nNorthern Québec at hydroelectric stations\nPoint Data\nVariable (1990 to present)\nVariable ( sub-daily to daily)\nNone\ndetails\n\n\nWhite Pass Railway & River Divisions dataset, Yukon\nYukon Research Centre\nStation data from archives\nThe upper Yukon River basin\nPoint data\n1902-1957\nDaily\nExcel files\ndetails\n\n\nSCDNA\nUniversity of Saskatchewan\nStation data and reanalyses blend\nNorth America\nPoint data\n1979-2018\nDaily\nNetCDF\ndetails\n\n\nCANGRD\nCRD/ECCC\nGridded observations\nCanada\n50 km x 50 km\n1948-2017 (anomalies)\nMonthly; Seasonal; Annual\nCSV; GeoJSON\ndetails\n\n\nANUSPLIN\nCFS/NRCan\nGridded observations\nCanada and North America\n(10 km x 10 km) and (2 km x 2 km)\n1950-2017\nDaily; Pentad; Monthly; Climatological means\nASCII; NetCDF\ndetails\n\n\nCRU TS Version 4\nCRU/University of East Anglia\nGridded observations\nGlobal (land only)\n0.5° x 0.5°\n1901–2018\nMonthly\nNetCDF\ndetails\n\n\nWorldClim2\nWorld Conservation Monitoring Centre/UNEP\nGridded observations\nGlobal (land only)\n10 arc minutes (~340 km);5 arc minutes;2.5 arc minutes; 30 arc seconds (1 km)\n1970-2000\nMonthly\nGeoTIFF\ndetails\n\n\nDaymet Version 4\nEnvironmental Sciences Division/Oak Ridge National Laboratory\nGridded observations\nNorth America (land only)\n1 km x 1 km\n1980-2019\nDaily\nNetCDF\ndetails\n\n\nPNWNAMET\nPCIC\nGridded observations\nNorth-western North America\n3.75 arc minutes (~6 km)\n1945-2012\nDaily\nASCII; NetCDF\ndetails\n\n\nMet1km\nNRCan\nBlend of gridded products\nCanada\n1 km x 1 km\n1901–2017\nDaily\nNone\ndetails\n\n\nERA5\nECMWF\nGlobal atmospheric reanalysis\nGlobal\n0.25° x 0.25°\n1950 to present\nHourly; Daily; Monthly\nGRIB;NetCDF\ndetails\n\n\nCFSR\nNCEP\nGlobal atmospheric reanalysis\nGlobal\n0.5° x 0.5°\n1979-2017\nSub-daily; Monthly\nGRIB\ndetails\n\n\nMERRA-2\nNASA\nGlobal atmospheric reanalysis\nGlobal\n½° latitude x ⅝° longitude\n1980 to present\nHourly; Daily; Monthly\nNetCDF\ndetails\n\n\nJRA-55\nJMA\nGlobal atmospheric reanalysis\nGlobal\n0.6258ᵒ x 0.6258ᵒ\n1957-2021\n3h; 6h; Daily; Monthly\nNetCDF\ndetails\n\n\nASRv2\nByrd Polar Research Center/The Ohio State University; UCAR/NCAR\nRegional reanalysis\nArctic\n15 km x 15 km\n2000-2016\n3h; Monthly\nNetCDF\ndetails\n\n\nNARR\nNCEP\nRegional reanalysis\nNorth America\n32 km x 32 km\n1979-2021\nSub-daily; Monthly\nGRIB\ndetails\n\n\nRDRSv2\nCCMEP/ECCC\nRegional reanalysis\nNorth America\n10 km x 10 km\n2000-2017(1980-1999 pending)\nHourly\nRPN\ndetails\n\n\n20CRv3\nCIRES; NOAA; DOE\nGlobal atmospheric reanalysis\nGlobal\nT254 (approximately 75 km at the equator)\n20CRv3.SI is available for years 1836-1980 and 20CRv3.MO is available for years 1981-2015\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nERA5-Land\nECMWF\nLand surface reanalysis/model\nGlobal (land only)\n0.1° x 0.1° (9 km)\n1950 to present\nHourly; Monthly\nGRIB; NetCDF\ndetails\n\n\nAgERA\nECMWF\nRe-gridded reanalysis\nGlobal (land only)\n0.1° x 0.1°\n1979 to present\nDaily\nNetCDF\ndetails\n\n\nAgCFSR\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nAgMERRA\nNASA\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1980-2010\nDaily\nNetCDF\ndetails\n\n\nGMFD\nPrinceton University\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.25° × 0.25°\n1948-2016\n3h; Daily; Monthly\nNetCDF\ndetails\n\n\nCRU JRA\nCRU/University of East Anglia\nRe-gridded reanalysis with corrections\nGlobal (land only)\n0.5° × 0.5°\n1901-2018\n6h\nNetCDF\ndetails\n\n\nS14FD\nDIAS\nRe-gridded reanalysis with corrections\nGlobal\n0.5° x 0.5°\n1958-2013\nDaily\nNetCDF\ndetails",
    "crumbs": [
      "Climate Datasets",
      "Temperature"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_management.html",
    "href": "sectors/enterprise_risk_management.html",
    "title": "Enterprise Risk Management",
    "section": "",
    "text": "Maybe consider this!\n\n\n\nThe following may need to become distinct sections!",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_management.html#infrastructure-condition-assessment",
    "href": "sectors/enterprise_risk_management.html#infrastructure-condition-assessment",
    "title": "Enterprise Risk Management",
    "section": "Infrastructure Condition Assessment",
    "text": "Infrastructure Condition Assessment",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_management.html#investment-prioritization",
    "href": "sectors/enterprise_risk_management.html#investment-prioritization",
    "title": "Enterprise Risk Management",
    "section": "Investment Prioritization",
    "text": "Investment Prioritization",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "sectors/enterprise_risk_management.html#vegetation-management",
    "href": "sectors/enterprise_risk_management.html#vegetation-management",
    "title": "Enterprise Risk Management",
    "section": "Vegetation Management",
    "text": "Vegetation Management",
    "crumbs": [
      "Electricity Sector Activities",
      "Enterprise Risk Management"
    ]
  },
  {
    "objectID": "datasets/wind/RDRS.html",
    "href": "datasets/wind/RDRS.html",
    "title": "Regional Deterministic Reforecast System - RDRS v2.1",
    "section": "",
    "text": "Overview\nEnvironment and Climate Change Canada has initiated the production of a 1980–2018, 10 km, North American precipitation and surface reanalysis. ERA-Interim is used to initialize the Global Deterministic Reforecast System (GDRS) at a 39 km resolution. Its output is then dynamically downscaled to 10 km by the Regional Deterministic Reforecast System (RDRS). Coupled with the RDRS, the Canadian Land Data Assimilation System (CaLDAS) and Precipitation Analysis (CaPA) are used to produce surface and precipitation analyses. All systems used are close to operational model versions and configurations.\nGasset, et al. (2021)\n\n\nTemperature Data\nRDRS v2.1 provides daily and hourly temperature data from 1980 onward, lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum lorem ipsum lorem ipsum lorem non-ipsum\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nsource\ndata type\nspatial domain\nspatial resolution\ntemporal coverage\ntime step\ndata format\n\n\n\n\n\nRDRSv2\nCCMEP/ECCC\nRegional reanalysis\nNorth America\n10 km x 10 km\n2000-2017(1980-1999 pending)\nHourly\nRPN\ndetails",
    "crumbs": [
      "Climate Datasets",
      "Wind",
      "Regional Deterministic Reforecast System - RDRS v2.1"
    ]
  },
  {
    "objectID": "datasets/wind/Wind_Datasets.html",
    "href": "datasets/wind/Wind_Datasets.html",
    "title": "Wind Datasets",
    "section": "",
    "text": "Introduction\nThis introduces wind data\n\n\nCode\nimport wind\n\nwind.do_something()\n\n\nHello wind!",
    "crumbs": [
      "Climate Datasets",
      "Wind"
    ]
  },
  {
    "objectID": "datasets/Point_Location_Compare.html",
    "href": "datasets/Point_Location_Compare.html",
    "title": "Observational Data at a point location: A tool for dataset comparison",
    "section": "",
    "text": "import xarray as xr\nimport xclim as xc\nfrom xclim.core import units\nfrom clisops.core.subset import subset_gridpoint\nimport matplotlib.pyplot as plt\nfrom datetime import date\nimport warnings\nwarnings.filterwarnings(action='ignore') # 'once'\nplt.style.use('seaborn-v0_8')\n\n# Inputs\nlat_in = 45\nlon_in = -72\n\nstart_date = date(1991,1,1)\nend_date = date(2020,12,31)\n\nfreq = 'annual'\n\ndatasets = {\n    \"ECCC_AHCCD_gen3_temperature\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen3_temperature.ncml\",\n    \"ECCC_AHCCD_gen2_precipitation\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen2_precipitation.ncml\",\n    \"NRCANMet_v2\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml\",\n    \"RDRSv2.1\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_RDRSv2.1_NAM.ncml\",\n    \"ERA5-Land\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_ERA5-Land_NAM.ncml\"\n    }\n\ndef aggregate(ds, var, freq='annual'):\n    freqs={\n        'month': 'MS',\n        'season': 'QS-DEC',\n        'annual': 'YS'\n    }\n    functs = {\n        'pr': xc.indicators.atmos.precip_average,\n        'tasmin': xc.indicators.atmos.tn_mean,\n        'tasmax': xc.indicators.atmos.tx_mean,\n    }\n    return functs[var](ds=ds, freq=freqs[freq])\n\n\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nfor idx, (name, url) in enumerate(datasets.items()):\n    ds = xr.open_dataset(url, chunks={'time': -1, 'lat':50, 'lon': 50}, decode_timedelta=False)\n    print(f\"{10*'-'} {name} {10*'-'}\") \n    #display(ds) \n    ds_pt = subset_gridpoint(ds,\n                             lat=lat_in,\n                             lon=lon_in,\n                             start_date=start_date.strftime('%Y-%m-%d'),\n                             end_date=end_date.strftime('%Y-%m-%d'),\n                             add_distance=True)\n    # # adjust temp units\n    # for var in ds_pt.data_vars:\n    #     if 'units' in ds_pt[var].attrs and ds_pt[var].units == 'K':\n    #         ds_pt[var] = units.convert_units_to(ds_pt[var], \"degC\")\n    \n    dist = f\"dist = {ds_pt.distance.values/1000:0.1f} km\"\n    print(dist)\n    \n    # Style:\n    color = f\"C{idx}\"\n    line_styles = {\"tasmin\": \"--\", \"tasmax\": \":\"}\n    \n    tmp_vars = ['tasmin', 'tasmax']\n    if all(var in ds.data_vars for var in tmp_vars):\n        for var in tmp_vars:\n\n            ds_var = aggregate(ds=ds_pt, var=var, freq=freq)\n\n            if 'units' in ds_var.attrs and ds_var.units == 'K':\n                ds_var = units.convert_units_to(ds_var, \"degC\")\n            #display(ds_pt)\n\n            ds_var.plot.line(ax=ax,\n                            linestyle=line_styles[var],\n                            color=color,\n                            label=f\"{name} - {dist}\" if var == 'tasmin' else None,\n                            add_legend=False\n                           )\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\nplt.title(f\"{freq.capitalize()} Minimum and Maximum Temperatures from Multiple Datasets between {start_date.year} and {end_date.year}\");\n\n---------- ECCC_AHCCD_gen3_temperature ----------\ndist = 22.9 km\n---------- ECCC_AHCCD_gen2_precipitation ----------\ndist = 43.3 km\n---------- NRCANMet_v2 ----------\ndist = 5.7 km\n---------- RDRSv2.1 ----------\ndist = 4.4 km\n\n\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\nsyntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\ncontext: Request^ Too Large: 32182.304 Mbytes, max=500.0\n\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[17], line 75\n     72                 ds_var = units.convert_units_to(ds_var, \"degC\")\n     73             #display(ds_pt)\n---&gt; 75             ds_var.plot.line(ax=ax,\n     76                             linestyle=line_styles[var],\n     77                             color=color,\n     78                             label=f\"{name} - {dist}\" if var == 'tasmin' else None,\n     79                             add_legend=False\n     80                            )\n     81 plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n     82 plt.title(f\"{freq.capitalize()} Minimum and Maximum Temperatures from Multiple Datasets between {start_date.year} and {end_date.year}\");\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/plot/accessor.py:136, in DataArrayPlotAccessor.line(self, *args, **kwargs)\n    134 @functools.wraps(dataarray_plot.line, assigned=(\"__doc__\",))\n    135 def line(self, *args, **kwargs) -&gt; list[Line3D] | FacetGrid[DataArray]:\n--&gt; 136     return dataarray_plot.line(self._da, *args, **kwargs)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/plot/dataarray_plot.py:505, in line(darray, row, col, figsize, aspect, size, ax, hue, x, y, xincrease, yincrease, xscale, yscale, xticks, yticks, xlim, ylim, add_legend, _labels, *args, **kwargs)\n    501 xplt, yplt, hueplt, hue_label = _infer_line_data(darray, x, y, hue)\n    503 # Remove pd.Intervals if contained in xplt.values and/or yplt.values.\n    504 xplt_val, yplt_val, x_suffix, y_suffix, kwargs = _resolve_intervals_1dplot(\n--&gt; 505     xplt.to_numpy(), yplt.to_numpy(), kwargs\n    506 )\n    507 xlabel = label_from_attrs(xplt, extra=x_suffix)\n    508 ylabel = label_from_attrs(yplt, extra=y_suffix)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/dataarray.py:831, in DataArray.to_numpy(self)\n    820 def to_numpy(self) -&gt; np.ndarray:\n    821     \"\"\"\n    822     Coerces wrapped data to numpy and returns a numpy.ndarray.\n    823 \n   (...)\n    829     DataArray.data\n    830     \"\"\"\n--&gt; 831     return self.variable.to_numpy()\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/namedarray/core.py:857, in NamedArray.to_numpy(self)\n    855 \"\"\"Coerces wrapped data to numpy and returns a numpy.ndarray\"\"\"\n    856 # TODO an entrypoint so array libraries can choose coercion method?\n--&gt; 857 return to_numpy(self._data)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/namedarray/pycompat.py:111, in to_numpy(data, **kwargs)\n    109 if is_chunked_array(data):\n    110     chunkmanager = get_chunked_array_type(data)\n--&gt; 111     data, *_ = chunkmanager.compute(data, **kwargs)\n    112 if isinstance(data, array_type(\"cupy\")):\n    113     data = data.get()\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:85, in DaskManager.compute(self, *data, **kwargs)\n     80 def compute(\n     81     self, *data: Any, **kwargs: Any\n     82 ) -&gt; tuple[np.ndarray[Any, _DType_co], ...]:\n     83     from dask.array import compute\n---&gt; 85     return compute(*data, **kwargs)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/dask/base.py:660, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)\n    657     postcomputes.append(x.__dask_postcompute__())\n    659 with shorten_traceback():\n--&gt; 660     results = schedule(dsk, keys, **kwargs)\n    662 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/indexing.py:578, in ImplicitToExplicitIndexingAdapter.__array__(self, dtype, copy)\n    574 def __array__(\n    575     self, dtype: np.typing.DTypeLike = None, /, *, copy: bool | None = None\n    576 ) -&gt; np.ndarray:\n    577     if Version(np.__version__) &gt;= Version(\"2.0.0\"):\n--&gt; 578         return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n    579     else:\n    580         return np.asarray(self.get_duck_array(), dtype=dtype)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/indexing.py:583, in ImplicitToExplicitIndexingAdapter.get_duck_array(self)\n    582 def get_duck_array(self):\n--&gt; 583     return self.array.get_duck_array()\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/indexing.py:794, in CopyOnWriteArray.get_duck_array(self)\n    793 def get_duck_array(self):\n--&gt; 794     return self.array.get_duck_array()\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/indexing.py:657, in LazilyIndexedArray.get_duck_array(self)\n    653     array = apply_indexer(self.array, self.key)\n    654 else:\n    655     # If the array is not an ExplicitlyIndexedNDArrayMixin,\n    656     # it may wrap a BackendArray so use its __getitem__\n--&gt; 657     array = self.array[self.key]\n    659 # self.array[self.key] is now a numpy array when\n    660 # self.array is a BackendArray subclass\n    661 # and self.key is BasicIndexer((slice(None, None, None),))\n    662 # so we need the explicit check for ExplicitlyIndexed\n    663 if isinstance(array, ExplicitlyIndexed):\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:103, in NetCDF4ArrayWrapper.__getitem__(self, key)\n    102 def __getitem__(self, key):\n--&gt; 103     return indexing.explicit_indexing_adapter(\n    104         key, self.shape, indexing.IndexingSupport.OUTER, self._getitem\n    105     )\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/core/indexing.py:1018, in explicit_indexing_adapter(key, shape, indexing_support, raw_indexing_method)\n    996 \"\"\"Support explicit indexing by delegating to a raw indexing method.\n    997 \n    998 Outer and/or vectorized indexers are supported by indexing a second time\n   (...)\n   1015 Indexing result, in the form of a duck numpy-array.\n   1016 \"\"\"\n   1017 raw_key, numpy_indices = decompose_indexer(key, shape, indexing_support)\n-&gt; 1018 result = raw_indexing_method(raw_key.tuple)\n   1019 if numpy_indices.tuple:\n   1020     # index the loaded np.ndarray\n   1021     indexable = NumpyIndexingAdapter(result)\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:116, in NetCDF4ArrayWrapper._getitem(self, key)\n    114     with self.datastore.lock:\n    115         original_array = self.get_array(needs_lock=False)\n--&gt; 116         array = getitem(original_array, key)\n    117 except IndexError as err:\n    118     # Catch IndexError in netCDF4 and return a more informative\n    119     # error message.  This is most often called when an unsorted\n    120     # indexer is used before the data is loaded from disk.\n    121     msg = (\n    122         \"The indexing operation you are attempting to perform \"\n    123         \"is not valid on netCDF4.Variable object. Try loading \"\n    124         \"your data into memory first by calling .load().\"\n    125     )\n\nFile /exec/braun/.conda/envs/energy-data/lib/python3.12/site-packages/xarray/backends/common.py:249, in robust_getitem(array, key, catch, max_retries, initial_delay)\n    247 for n in range(max_retries + 1):\n    248     try:\n--&gt; 249         return array[key]\n    250     except catch:\n    251         if n == max_retries:\n\nFile src/netCDF4/_netCDF4.pyx:5079, in netCDF4._netCDF4.Variable.__getitem__()\n\nFile src/netCDF4/_netCDF4.pyx:6051, in netCDF4._netCDF4.Variable._get()\n\nFile src/netCDF4/_netCDF4.pyx:2164, in netCDF4._netCDF4._ensure_nc_success()\n\nRuntimeError: NetCDF: Authorization failure\n\n\n\n\n\n\n\n\n\n\n\nds = xr.open_dataset(\"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_RDRSv2.1_NAM.ncml\", chunks={'time': -1, 'lat': 1, 'lon': 1}, decode_timedelta=False)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 418GB\nDimensions:       (rlat: 800, rlon: 706, time: 14245)\nCoordinates:\n  * rlat          (rlat) float32 3kB -46.17 -46.08 -45.99 ... 25.56 25.65 25.74\n  * rlon          (rlon) float32 3kB 324.6 324.7 324.8 ... 387.9 388.0 388.1\n    rotated_pole  float32 4B ...\n  * time          (time) datetime64[ns] 114kB 1980-01-01 ... 2018-12-31\n    lat           (rlat, rlon) float32 2MB dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;\n    lon           (rlat, rlon) float32 2MB dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;\nData variables: (12/16)\n    lakeFrac      (rlat, rlon) float32 2MB dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;\n    sftlf         (rlat, rlon) float32 2MB dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;\n    sftof         (rlat, rlon) float32 2MB dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;\n    tas           (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    tasmin        (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    tasmax        (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    ...            ...\n    psl           (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    ps            (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    huss          (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    hursmin       (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    hursmax       (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\n    hurs          (time, rlat, rlon) float32 32GB dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;\nAttributes: (12/29)\n    Conventions:          CF-1.8\n    Notes:                Created from the Gem_geophy.fst file provided by Mi...\n    doi:                  https://doi.org/10.5194/hess-25-4917-2021\n    frequency:            fx\n    license:              https://eccc-msc.github.io/open-data/licence/readme...\n    organisation:         ECCC\n    ...                   ...\n    institute_id:         ECCC\n    dataset_id:           RDRSv2.1\n    abstract:             Environment and Climate Change Canada has initiated...\n    dataset_description:  https://doi.org/10.5194/hess-25-4917-2021\n    license_type:         permissive\n    citation:             Gasset, N., Fortin, V., Dimitrijevic, M., Carrera, ...xarray.DatasetDimensions:rlat: 800rlon: 706time: 14245Coordinates: (6)rlat(rlat)float32-46.17 -46.08 ... 25.65 25.74long_name :latitude in rotated pole gridaxis :Yeccc_grid_definition :grtyp: E, ig1: 1470, ig2: 560, ig3: 54400, ig4: 46560standard_name :grid_latitudeunits :degreesarray([-46.170002, -46.08    , -45.99    , ...,  25.56    ,  25.65    ,\n        25.74    ], dtype=float32)rlon(rlon)float32324.6 324.7 324.8 ... 388.0 388.1long_name :longitude in rotated pole gridaxis :Xeccc_grid_definition :grtyp: E, ig1: 1470, ig2: 560, ig3: 54400, ig4: 46560standard_name :grid_longitudeunits :degreesarray([324.60278, 324.69278, 324.78278, ..., 387.87277, 387.96277, 388.0528 ],\n      dtype=float32)rotated_pole()float32...long_name :coordinates of the rotated North Poleearth_radius :6371220.0grid_mapping_name :rotated_latitude_longitudegrid_north_pole_latitude :31.758316040039062grid_north_pole_longitude :87.59703063964844longitude_of_prime_meridian :0.0north_pole_grid_longitude :0.0[1 values with dtype=float32]time(time)datetime64[ns]1980-01-01 ... 2018-12-31array(['1980-01-01T00:00:00.000000000', '1980-01-02T00:00:00.000000000',\n       '1980-01-03T00:00:00.000000000', ..., '2018-12-29T00:00:00.000000000',\n       '2018-12-30T00:00:00.000000000', '2018-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')lat(rlat, rlon)float32dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;long_name :latitudeeccc_grid_definition :grtyp: Z, ig1: 96709, ig2: 42598, ig3: 0, ig4: 0standard_name :latitudeunits :degrees_north\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.15 MiB\n2.15 MiB\n\n\nShape\n(800, 706)\n(800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         706 800\n\n\n\n\nlon(rlat, rlon)float32dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;long_name :longitudeeccc_grid_definition :grtyp: Z, ig1: 96709, ig2: 42598, ig3: 0, ig4: 0standard_name :longitudeunits :degrees_east\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.15 MiB\n2.15 MiB\n\n\nShape\n(800, 706)\n(800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         706 800\n\n\n\n\nData variables: (16)lakeFrac(rlat, rlon)float32dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;long_name :Lake Area Fractiongrid_mapping :rotated_polestandard_name :lake_area_fraction_ChunkSizes :[50 50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.15 MiB\n2.15 MiB\n\n\nShape\n(800, 706)\n(800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         706 800\n\n\n\n\nsftlf(rlat, rlon)float32dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;long_name :Land Area Fractiongrid_mapping :rotated_polestandard_name :land_area_fraction_ChunkSizes :[50 50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.15 MiB\n2.15 MiB\n\n\nShape\n(800, 706)\n(800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         706 800\n\n\n\n\nsftof(rlat, rlon)float32dask.array&lt;chunksize=(800, 706), meta=np.ndarray&gt;long_name :Sea Area Fractiongrid_mapping :rotated_polestandard_name :sea_area_fraction_ChunkSizes :[50 50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.15 MiB\n2.15 MiB\n\n\nShape\n(800, 706)\n(800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         706 800\n\n\n\n\ntas(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre temperaturecell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TT_1.5mstandard_name :air_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\ntasmin(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre temperaturecell_methods :time: minimum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TT_1.5mstandard_name :air_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\ntasmax(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre temperaturecell_methods :time: maximum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TT_1.5mstandard_name :air_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\npr(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Precipitationcell_methods :time: mean (interval: 1 day)comments :Converted from Total Precipitation using a density of 1000 kg/m³.grid_mapping :rotated_poleoriginal_long_name :Total Precipitationoriginal_variable :RDRS_v2.1_A_PR0_SFCstandard_name :precipitation_fluxunits :kg m-2 s-1_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\ntdpsmin(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre dewpoint temperaturecell_methods :time: minimum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TD_1.5mstandard_name :dew_point_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\ntdpsmax(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre dewpoint temperaturecell_methods :time: maximum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TD_1.5mstandard_name :dew_point_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\ntdps(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :1.5 metre dewpoint temperaturecell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_TD_1.5mstandard_name :dew_point_temperatureunits :K_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\npsl(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Sea Level Pressurecell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_PN_SFCstandard_name :air_pressure_at_sea_levelunits :Pa_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nps(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Surface Air Pressurecell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_P0_SFCstandard_name :surface_air_pressureunits :Pa_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nhuss(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Near-Surface Specific Humidity (1.5m)cell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_HU_1.5mstandard_name :specific_humidityunits :1_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nhursmin(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Near-Surface Relative Humidity (1.5m)cell_methods :time: minimum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_HR_1.5mstandard_name :relative_humidityunits :%_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nhursmax(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Near-Surface Relative Humidity (1.5m)cell_methods :time: maximum (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_HR_1.5mstandard_name :relative_humidityunits :%_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nhurs(time, rlat, rlon)float32dask.array&lt;chunksize=(14245, 800, 706), meta=np.ndarray&gt;long_name :Near-Surface Relative Humidity (1.5m)cell_methods :time: mean (interval: 1 day)grid_mapping :rotated_poleoriginal_variable :RDRS_v2.1_P_HR_1.5mstandard_name :relative_humidityunits :%_ChunkSizes :[1461   50   50]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n29.97 GiB\n29.97 GiB\n\n\nShape\n(14245, 800, 706)\n(14245, 800, 706)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         706 800 14245\n\n\n\n\nIndexes: (3)rlatPandasIndexPandasIndex(Index([ -46.17000198364258,  -46.08000183105469,   -45.9900016784668,\n       -45.900001525878906, -45.810001373291016, -45.720001220703125,\n       -45.630001068115234, -45.540000915527344,  -45.45000076293945,\n        -45.36000061035156,\n       ...\n         24.93000030517578,  25.020000457763672,  25.110000610351562,\n        25.200000762939453,  25.290000915527344,    25.3799991607666,\n        25.469999313354492,  25.559999465942383,  25.649999618530273,\n        25.739999771118164],\n      dtype='float32', name='rlat', length=800))rlonPandasIndexPandasIndex(Index([  324.602783203125,  324.6927795410156, 324.78277587890625,\n        324.8727722167969,  324.9627685546875, 325.05279541015625,\n        325.1427917480469,  325.2327880859375,  325.3227844238281,\n       325.41278076171875,\n       ...\n        387.2427673339844,  387.3327941894531, 387.42279052734375,\n        387.5127868652344,   387.602783203125,  387.6927795410156,\n       387.78277587890625,  387.8727722167969,  387.9627685546875,\n       388.05279541015625],\n      dtype='float32', name='rlon', length=706))timePandasIndexPandasIndex(DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n               '1980-01-09', '1980-01-10',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='time', length=14245, freq=None))Attributes: (29)Conventions :CF-1.8Notes :Created from the Gem_geophy.fst file provided by Milena Dimitrijevic (ECCC).doi :https://doi.org/10.5194/hess-25-4917-2021frequency :fxlicense :https://eccc-msc.github.io/open-data/licence/readme_en/organisation :ECCCprocessing_level :rawproject :rdrs-v21realm :atmossource :RDRS v2.1table_id :ECtype :reanalysisversion :v2.1format :netcdfRemarks :Original variable names are following the convention &lt;Product&gt;_&lt;Type:A=Analysis,P=Prediction&gt;_&lt;ECCC name&gt;_&lt;Level/Tile/Category&gt;. Variables with level '10000' are at surface level. The height [m] of variables with level '0XXXX' needs to be inferrred using the corresponding fields of geopotential height (GZ_0XXXX-GZ_10000). The variables UUC, VVC, UVC, and WDC are not modelled but inferred from UU and VV for convenience of the users. Precipitation (PR) is reported as 6-hr accumulations for CaPA_fine and CaPA_coarse. Precipitation (PR) are accumulations since beginning of the forecast for GEPS, GDPS, REPS, RDPS, HRDPS, and CaLDAS. The re-analysis product RDRS_v2 contains two variables for precipitation: 'RDRS_v2_P_PR0_SFC' is the model precipitation (trial field used by CaPA) and 'RDRS_v2_A_PR0_SFC' is precipitations adjusted with CaPA 24h precipitation (as in 'RDRS_P_PR0_SFC'). Please be aware that the baseflow 'O1' of the current version of WCPS is not reliable during the spring melt period.data_specs_version :00.00.08history :2023-03-22 12:29:59.228378: Variables converted from original files using miranda.convert.dataset_corrections. [2023-03-22 12:29:59.228362] Converted variables and modified metadata for CF-like compliance: Resampled time with `freq=H`. Converted variable `RDRS_v2.1_P_TT_1.5m` to CF-compliant units (`K`). Transformed variable `RDRS_v2.1_P_TT_1.5m` values using method `None`.table_date :12 December 2022terms_of_use :When accessing RDRS v2.1 data via the PAVICS platform users should also acknowledge The Canadian Surface Prediction Archive (CaSPAr) as the original data source (https://caspar-data.ca/, https://doi.org/10.1175/BAMS-D-19-0143.1)contact :miranda_version :0.4.0title :Regional Deterministic Reforecast System - RDRS v2.1 : dailyinstitute :Environment and Climate Change Canadainstitute_id :ECCCdataset_id :RDRSv2.1abstract :Environment and Climate Change Canada has initiated the production of a 1980–2018, 10 km, North American precipitation and surface reanalysis. ERA-Interim is used to initialize the Global Deterministic Reforecast System (GDRS) at a 39 km resolution. Its output is then dynamically downscaled to 10 km by the Regional Deterministic Reforecast System (RDRS). Coupled with the RDRS, the Canadian Land Data Assimilation System (CaLDAS) and Precipitation Analysis (CaPA) are used to produce surface and precipitation analyses. All systems used are close to operational model versions and configurations.dataset_description :https://doi.org/10.5194/hess-25-4917-2021license_type :permissivecitation :Gasset, N., Fortin, V., Dimitrijevic, M., Carrera, M., Bilodeau, B., Muncaster, R., Gaborit, É., Roy, G., Pentcheva, N., Bulat, M., Wang, X., Pavlovic, R., Lespinas, F., Khedhaouiria, D., and Mai, J. (2021): A 10km North American precipitation and land-surface reanalysis based on the GEM atmospheric model, Hydrol. Earth Syst. Sci., 25, 4917–4945\n\n\n\nplt.style.available\n\n\nimport numpy as np\nimport pandas as pd\nimport hvplot.pandas  # hvplot for plotting\nimport panel as pn\nimport holoviews as hv\n\n# Initialize Panel and Holoviews\n#pn.extension('bokeh', 'matplotlib')\nhv.extension('bokeh')\n\n# Generate example data\nx = np.linspace(0, 10, 500)\ny = np.sin(x)\ndata = pd.DataFrame({'x': x, 'y': y, 'feature1': np.cos(x), 'feature2': np.tan(x / 10)})\n\n# Widgets\nxlim_slider = pn.widgets.RangeSlider(name=\"X-Axis Limits\", start=0, end=10, value=(0, 10), step=0.1)\nlat_input = pn.widgets.TextInput(name=\"Latitude\", placeholder=\"Enter Latitude\")\nlon_input = pn.widgets.TextInput(name=\"Longitude\", placeholder=\"Enter Longitude\")\nfeature1_dropdown = pn.widgets.Select(name=\"Feature 1\", options=['y', 'feature1', 'feature2'])\nfeature2_dropdown = pn.widgets.Select(name=\"Feature 2\", options=['y', 'feature1', 'feature2'])\n\n# Callback function for live updates\ndef update_plot(xlim, feature1, feature2):\n    x_start, x_end = xlim\n    filtered_data = data[(data['x'] &gt;= x_start) & (data['x'] &lt;= x_end)]\n    return filtered_data.hvplot(x='x', y=[feature1, feature2], ylabel=\"Value\", title=\"Interactive Plot\")\n\n# Dynamic plot panel\ndynamic_plot = pn.bind(update_plot, xlim=xlim_slider, feature1=feature1_dropdown, feature2=feature2_dropdown)\n\n# Layout\ndashboard = pn.Column(\n    pn.pane.Markdown(\"## Interactive Dashboard with Panel\"),\n    pn.Row(\n        pn.Column(\"### Controls\", xlim_slider, lat_input, lon_input, feature1_dropdown, feature2_dropdown),\n        pn.Column(\"### Plot\", dynamic_plot),\n    ),\n)\n\n# Running in a Jupyter Notebook\ndashboard  # This will display the dashboard in a separate tab or browser window"
  },
  {
    "objectID": "sectors/forest_fire_monitoring_and_awareness.html#second-level-heading",
    "href": "sectors/forest_fire_monitoring_and_awareness.html#second-level-heading",
    "title": "Forest Fire Monitoring and Awareness",
    "section": "Second Level Heading",
    "text": "Second Level Heading\nbla bla\n\nThird level Heading\nhaha haha\n\nFourth Level Heading\nIs this still showing in the TOC?\nAnd with that I’ll add some code right here:\n\nimport beer\nimport time\nimport user\n\nif time &gt; \"16:00\":\n    beer = True\n    user.drink(beer)",
    "crumbs": [
      "Electricity Sector Activities",
      "Forest Fire Monitoring and Awareness"
    ]
  },
  {
    "objectID": "datasets/tools/Point_Location_Compare.html",
    "href": "datasets/tools/Point_Location_Compare.html",
    "title": "A tool for dataset comparison: Observational Data at a point location",
    "section": "",
    "text": "This page contains Python code that can extract and display historical climate data from different sources at a point location for comparison. The code can be run on the PAVICS platform or a locally configured Python environment with Jupyter Notebook or Jupyter Lab functionality enabled. It relys on the data available on PAVICS, but other data from other sources may be introduced.\nTwo versions are shown:\n\nA simple script that may be modified by the user to control the output figure.\nA script that generates an interactive dashboard with widgets for the user to control the output of the figure.\n\n\n\n\n\n\n\nNote\n\n\n\nThe code sections below can not be executed on this web page. For them to be run they will need to be copied to a Jupyter Notebook.",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools",
      "A tool for dataset comparison: Observational Data at a point location"
    ]
  },
  {
    "objectID": "datasets/tools/Point_Location_Compare.html#overview",
    "href": "datasets/tools/Point_Location_Compare.html#overview",
    "title": "A tool for dataset comparison: Observational Data at a point location",
    "section": "",
    "text": "This page contains Python code that can extract and display historical climate data from different sources at a point location for comparison. The code can be run on the PAVICS platform or a locally configured Python environment with Jupyter Notebook or Jupyter Lab functionality enabled. It relys on the data available on PAVICS, but other data from other sources may be introduced.\nTwo versions are shown:\n\nA simple script that may be modified by the user to control the output figure.\nA script that generates an interactive dashboard with widgets for the user to control the output of the figure.\n\n\n\n\n\n\n\nNote\n\n\n\nThe code sections below can not be executed on this web page. For them to be run they will need to be copied to a Jupyter Notebook.",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools",
      "A tool for dataset comparison: Observational Data at a point location"
    ]
  },
  {
    "objectID": "datasets/tools/Point_Location_Compare.html#a-simple-script",
    "href": "datasets/tools/Point_Location_Compare.html#a-simple-script",
    "title": "A tool for dataset comparison: Observational Data at a point location",
    "section": "A simple script",
    "text": "A simple script\nThis script generates a figure to compare datasets of historical climate.\n\nFirst we need to import libraries and define the data\nThe following section determines the content of the figure in terms of the datasets, the point location, the time period and the frequency.\n\n\nCode\nimport xarray as xr\nimport xclim as xc\nfrom xclim.core import units\nfrom clisops.core.subset import subset_gridpoint\nimport matplotlib.pyplot as plt\nfrom datetime import date\nfrom dask.diagnostics import ProgressBar\nimport warnings\nwarnings.filterwarnings(action='ignore')\n# plt.style.available\nplt.style.use('seaborn-v0_8')\n\n# Inputs\nlat_in = 45.0\nlon_in = -72.0\n\nstart_date = date(1991,1,1)\nend_date = date(2020,12,31)\n\nfreq = 'year'\n\ndatasets = {\n    \"ECCC_AHCCD_gen3_temperature\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen3_temperature.ncml\",\n    #\"ECCC_AHCCD_gen2_precipitation\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen2_precipitation.ncml\",\n    \"NRCANMet_v2\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml\",\n    \"RDRSv2.1\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_RDRSv2.1_NAM.ncml\",\n    \"ERA5-Land\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_ERA5-Land_NAM.ncml\"\n    }\n\ndef aggregate(ds, var, freq='annual'):\n    freqs={\n        'month': 'MS',\n        'season': 'QS-DEC',\n        'year': 'YS'\n    }\n    functs = {\n        'pr': xc.indicators.atmos.precip_average,\n        'tasmin': xc.indicators.atmos.tn_mean,\n        'tasmax': xc.indicators.atmos.tx_mean,\n    }\n    return functs[var](ds=ds, freq=freqs[freq])\n\n\n\n\nIn the second step we create the figure\nThe next section of code will load the data for the selected location, time period, location and frequency and generate the figure.\n\n\nCode\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nfor idx, (name, url) in enumerate(datasets.items()):\n    ds = xr.open_dataset(url, chunks={'time': -1, 'lat': 50, 'lon': 50}, decode_timedelta=False)\n    print(f\"Loading {name} ...\") \n    #display(ds) \n    ds_pt = subset_gridpoint(ds,\n                             lat=lat_in,\n                             lon=lon_in,\n                             start_date=start_date.strftime('%Y-%m-%d'),\n                             end_date=end_date.strftime('%Y-%m-%d'),\n                             add_distance=True)\n    \n    dist = f\"dist = {ds_pt.distance.values/1000:0.1f} km\"\n    #print(dist)\n    \n    # Style\n    color = f\"C{idx}\"\n    line_styles = {\"tasmin\": \":\", \"tasmax\": \"--\"}\n    \n    tmp_vars = ['tasmin', 'tasmax']\n    if all(var in ds.data_vars for var in tmp_vars):\n        for var in tmp_vars:\n\n            ds_var = aggregate(ds=ds_pt, var=var, freq=freq)\n\n            if 'units' in ds_var.attrs and ds_var.units == 'K':\n                ds_var = units.convert_units_to(ds_var, \"degC\")\n            #display(ds_pt)\n\n            ds_var.plot.line(ax=ax,\n                            linestyle=line_styles[var],\n                            color=color,\n                            label=f\"{name} - {dist}\" if var == 'tasmin' else None,\n                            add_legend=False\n                           )\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\nax.set_ylabel(f\"Minimum and maximum\\n{freq} temperature [˚C]\")\nplt.title(f\"{freq.capitalize()} Minimum and Maximum Temperatures from Multiple Datasets between {start_date.year} and {end_date.year}\");\n\n\nLoading ECCC_AHCCD_gen3_temperature ...\nLoading NRCANMet_v2 ...\nLoading RDRSv2.1 ...\nLoading ERA5-Land ...\n\n\n\n\n\n\n\n\n\nModifying the two code sections above allows the user to adjust the content of the figure.",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools",
      "A tool for dataset comparison: Observational Data at a point location"
    ]
  },
  {
    "objectID": "datasets/tools/Point_Location_Compare.html#a-script-to-create-an-interactive-dashboard",
    "href": "datasets/tools/Point_Location_Compare.html#a-script-to-create-an-interactive-dashboard",
    "title": "A tool for dataset comparison: Observational Data at a point location",
    "section": "A script to create an interactive dashboard",
    "text": "A script to create an interactive dashboard\n\nPreparations for the dashboard\nThe following section of code defines functions that will be used by the dashboard to update the figure based on user input.\n\n\nCode\n# Callback function to create the Matplotlib plot\ndef create_plot(xlim, freq, var):\n    \n    start, end = xlim\n    start = date(start,1,1)\n    end = date(end,12,31)\n    \n    fig, ax = plt.subplots(figsize=(9,3))\n    \n    for idx, (name, file) in enumerate(data_files.items()):\n        # Style:\n        color = f\"C{idx}\"\n        line_styles = {\"tasmin\": \":\", \"tasmax\": \"--\"}\n\n        tmp_vars = ['tasmin', 'tasmax']\n        ds = xr.open_dataset(file)\n        dist = f\"dist = {ds.distance.values/1000:0.1f} km\"\n        if all(var in ds.data_vars for var in tmp_vars):\n            for var in tmp_vars:\n\n                ds_var = aggregate(ds=ds, var=var, freq=freq)\n\n                if 'units' in ds_var.attrs and ds_var.units == 'K':\n                    ds_var = units.convert_units_to(ds_var, \"degC\")\n                #display(ds_pt)\n\n                ds_var.sel(time=slice(start, end)).plot.line(ax=ax,\n                                linestyle=line_styles[var],\n                                linewidth=1,\n                                color=color,\n                                label=f\"{name} - {dist}\" if var == 'tasmin' else None,\n                                add_legend=False\n                               )\n    ax.set_ylabel(f\"Minimum and maximum\\n{freq} temperature [˚C]\")\n    ax.xaxis.label.set_fontsize(8)  # Update x-axis label font size\n    ax.yaxis.label.set_fontsize(8)  # Update y-axis label font size\n    ax.tick_params(axis='x', labelsize=6)  # Update x-axis tick labels font size\n    ax.tick_params(axis='y', labelsize=6)  # Update y-axis tick labels font size\n    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize=6)\n    plt.title(f\"{freq.capitalize()} Minimum and Maximum Temperatures from Multiple Datasets between {start.year} and {end.year}\", fontsize=8);\n    \n    plt.close(fig)  # Prevent Matplotlib from displaying the figure immediately\n    return fig\n\n# callback function to exract data for point location.\ndef extract_data(lat, lon):\n    \n    # ToDo: delete old points data!\n    data_files = {}\n    for idx, (name, url) in enumerate(datasets.items()):\n        ds = xr.open_dataset(url, chunks={'time': -1, 'lat': 50, 'lon': 50}, decode_timedelta=False)\n        print(f\"{10*'-'} Reading {name} {10*'-'}\") \n        #display(ds) \n        ds_pt = subset_gridpoint(ds,\n                                 lat=lat,\n                                 lon=lon,\n                                 add_distance=True)\n        #display(ds_pt)\n        file = f'tmp/{name}_lat{lat}_lon{lon}.nc'\n        #print(f\"Writing {file} ...\")\n        ds_pt.to_netcdf(file)\n        data_files[name] = file\n    return data_files\n\n\n\n\nLoading the data\nThe next block of code loads data from a default grid point.\n\n\nCode\n# ToDo: load with AHCCD data\ndatasets = {\n    #\"ECCC_AHCCD_gen3_temperature\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen3_temperature.ncml\",\n    #\"ECCC_AHCCD_gen2_precipitation\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen2_precipitation.ncml\",\n    \"NRCANMet_v2\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml\",\n    \"RDRSv2.1\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_RDRSv2.1_NAM.ncml\",\n    \"ERA5-Land\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_ERA5-Land_NAM.ncml\"\n    }\n\nwith ProgressBar():\n    data_files = extract_data(lat_in, lon_in)\n\nprint(data_files)\n\n\n---------- Reading NRCANMet_v2 ----------\n[########################################] | 100% Completed | 23.85 s\n---------- Reading RDRSv2.1 ----------\n[########################################] | 100% Completed | 302.90 ms\n[########################################] | 100% Completed | 101.07 ms\n[########################################] | 100% Completed | 101.28 ms\n[########################################] | 100% Completed | 302.42 ms\n[########################################] | 100% Completed | 14.29 s\n---------- Reading ERA5-Land ----------\n[########################################] | 100% Completed | 47.41 s\n{'NRCANMet_v2': 'tmp/NRCANMet_v2_lat45.0_lon-72.0.nc', 'RDRSv2.1': 'tmp/RDRSv2.1_lat45.0_lon-72.0.nc', 'ERA5-Land': 'tmp/ERA5-Land_lat45.0_lon-72.0.nc'}\n\n\n\n\nCreating the interactive dashboard\nThe following section uses the panel library to create a user interface to interactively modify the figure. It uses the above functions to do so.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport panel as pn\n\n# Initialize Panel\npn.extension()\n\n# Widgets\nxlim_slider = pn.widgets.RangeSlider(name=\"Years\", start=1950, end=2025, value=(1950, 2025), step=1)\nlat_input = pn.widgets.TextInput(name=\"Latitude\", placeholder=\"Enter Latitude\", value=str(lat_in), width=125)\nlon_input = pn.widgets.TextInput(name=\"Longitude\", placeholder=\"Enter Longitude\", value=str(lon_in), width=125)\nfreq_dropdown = pn.widgets.Select(name=\"Frequency\", options=['month', 'season', 'year'], value='year', width=100)\nvar_dropdown = pn.widgets.Select(name=\"Variable\", options=['Temperature', 'Precipitation'], width=150)\nvar_stats = pn.widgets.Select(name=\"Statistic\", options=['mean', 'maximum', 'minimum'], width=150)\n\n# Dynamic Matplotlib plot\ndynamic_plot = pn.bind(create_plot, xlim=xlim_slider, freq=freq_dropdown, var=var_dropdown)\n\n# Layout\ncontrols = pn.Row(\"### Controls\", xlim_slider, lat_input, lon_input, freq_dropdown, var_dropdown, var_stats)\ndashboard = pn.Column(controls, pn.pane.Matplotlib(dynamic_plot, tight=True))\n\n# Serve the dashboard\ndashboard",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools",
      "A tool for dataset comparison: Observational Data at a point location"
    ]
  },
  {
    "objectID": "datasets/tools/Untitled.html",
    "href": "datasets/tools/Untitled.html",
    "title": "Analysis Support Tools",
    "section": "",
    "text": "This section contains pages with Python code that can be used to support the analysis and selection of climate datasets for applications in the electricity sector."
  },
  {
    "objectID": "datasets/tools/Analysis_Support_Tools.html",
    "href": "datasets/tools/Analysis_Support_Tools.html",
    "title": "Analysis Support Tools",
    "section": "",
    "text": "This section contains pages with Python code that can be used to support the analysis and selection of climate datasets for applications in the electricity sector.",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools"
    ]
  },
  {
    "objectID": "datasets/Climate_Dataset_Overview.html",
    "href": "datasets/Climate_Dataset_Overview.html",
    "title": "An Overview of Climate Data",
    "section": "",
    "text": "Note\n\n\n\nThe structure of this section may be organized by:\n\nClimate Variable\nDatasets\n\nTBD",
    "crumbs": [
      "Climate Datasets"
    ]
  },
  {
    "objectID": "datasets/Climate_Dataset_Overview.html#climate-data-sources",
    "href": "datasets/Climate_Dataset_Overview.html#climate-data-sources",
    "title": "An Overview of Climate Data",
    "section": "Climate Data Sources",
    "text": "Climate Data Sources\nGenerally, climate data can be sourced from historical observation of climate using instrumentation or from climate model simulations. In the context of electricity system planning and design, future climatic conditions should be of primary interest, but observed historical climate data and products derived thereof may also be employed or used in the development of adequate future climate information.\nObserved data is provided as point information at station locations. To provide continuous fields of climate information, station data can be interpolated spatially to produce gridded historical data. They provide a portrait of climate beyond the stations point locations but are impacted by potential interpolation errors, particularly in data sparce regions, or in regions of complex topography (e.g. mountainous areas). The approach that attempts to overcome these drawbacks is the reproduction of historical climate through the combination of a maximum of available climate information with a physical climate simulation approach known as climate reanalysis. Reanalysis products have substantially improved over recent years and are often used as surrogates for observational data in climate science and studies.\nObservational data and reanalysis data provide a representation of the actual evolution and sequence of events as they occurred and provide robust estimates of climate when averaged over climatic periods (usually 30 years). Note, however, that due to natural climate variability, climate estimates would shift with slight temporal shifts of the period, or the data being used.\nSimulated data from climate models used for electricity system planning and design should be sourced from internationally coordinated ensembles of climate model simulations or products derived thereof. These simulations typically cover multiple decades and are available for historical and future periods. They are fully consistent in time and space and are provided on grids. The grid resolution depends on the model or the data product.\nLike observational data, bias-adjusted historical climate simulations may be used to derive climate estimates of historical climate. These estimates will not be identical to climate estimates from observed data yet will generally fall into the range of natural variability of the observed climate. Since climate model simulations extend into the future, estimates for future climate may also be derived. It is important to note that the sequence of events produced by a historical climate simulation is distinct from the sequence of historically observed events, although their respective climate estimate is the robust characteristic they have in common.",
    "crumbs": [
      "Climate Datasets"
    ]
  },
  {
    "objectID": "datasets/tools/Point_Location_Compare.html#a-simple-script-for-genrating-a-figure-to-compare-datasets-of-historical-climate",
    "href": "datasets/tools/Point_Location_Compare.html#a-simple-script-for-genrating-a-figure-to-compare-datasets-of-historical-climate",
    "title": "A tool for dataset comparison: Observational Data at a point location",
    "section": "A simple script for genrating a figure to compare datasets of historical climate",
    "text": "A simple script for genrating a figure to compare datasets of historical climate\n\nFirst we need to import libraries and define the data\nThe following section determines the content of the figure in terms of the datasets, the point location, the time period and the frequency.\n\n\nCode\nimport xarray as xr\nimport xclim as xc\nfrom xclim.core import units\nfrom clisops.core.subset import subset_gridpoint\nimport matplotlib.pyplot as plt\nfrom datetime import date\nfrom dask.diagnostics import ProgressBar\nimport warnings\nwarnings.filterwarnings(action='ignore')\n# plt.style.available\nplt.style.use('seaborn-v0_8')\n\n# Inputs\nlat_in = 45.0\nlon_in = -72.0\n\nstart_date = date(1991,1,1)\nend_date = date(2020,12,31)\n\nfreq = 'year'\n\ndatasets = {\n    \"ECCC_AHCCD_gen3_temperature\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen3_temperature.ncml\",\n    #\"ECCC_AHCCD_gen2_precipitation\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen2_precipitation.ncml\",\n    \"NRCANMet_v2\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml\",\n    \"RDRSv2.1\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_RDRSv2.1_NAM.ncml\",\n    \"ERA5-Land\": \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/day_ERA5-Land_NAM.ncml\"\n    }\n\ndef aggregate(ds, var, freq='annual'):\n    freqs={\n        'month': 'MS',\n        'season': 'QS-DEC',\n        'year': 'YS'\n    }\n    functs = {\n        'pr': xc.indicators.atmos.precip_average,\n        'tasmin': xc.indicators.atmos.tn_mean,\n        'tasmax': xc.indicators.atmos.tx_mean,\n    }\n    return functs[var](ds=ds, freq=freqs[freq])\n\n\n\n\nIn the second step we create the figure\nThe next section of code will load the data for the selected location, time period, location and frequency and generate the figure.\n\n\nCode\nfig, ax = plt.subplots(1,1, figsize=(15,5))\nfor idx, (name, url) in enumerate(datasets.items()):\n    ds = xr.open_dataset(url, chunks={'time': -1, 'lat': 50, 'lon': 50}, decode_timedelta=False)\n    print(f\"Loading {name} ...\") \n    #display(ds) \n    ds_pt = subset_gridpoint(ds,\n                             lat=lat_in,\n                             lon=lon_in,\n                             start_date=start_date.strftime('%Y-%m-%d'),\n                             end_date=end_date.strftime('%Y-%m-%d'),\n                             add_distance=True)\n    \n    dist = f\"dist = {ds_pt.distance.values/1000:0.1f} km\"\n    #print(dist)\n    \n    # Style\n    color = f\"C{idx}\"\n    line_styles = {\"tasmin\": \":\", \"tasmax\": \"--\"}\n    \n    tmp_vars = ['tasmin', 'tasmax']\n    if all(var in ds.data_vars for var in tmp_vars):\n        for var in tmp_vars:\n\n            ds_var = aggregate(ds=ds_pt, var=var, freq=freq)\n\n            if 'units' in ds_var.attrs and ds_var.units == 'K':\n                ds_var = units.convert_units_to(ds_var, \"degC\")\n            #display(ds_pt)\n\n            ds_var.plot.line(ax=ax,\n                            linestyle=line_styles[var],\n                            color=color,\n                            label=f\"{name} - {dist}\" if var == 'tasmin' else None,\n                            add_legend=False\n                           )\nplt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\nax.set_ylabel(f\"Minimum and maximum\\n{freq} temperature [˚C]\")\nplt.title(f\"{freq.capitalize()} Minimum and Maximum Temperatures from Multiple Datasets between {start_date.year} and {end_date.year}\");\n\n\nLoading ECCC_AHCCD_gen3_temperature ...\nLoading NRCANMet_v2 ...\nLoading RDRSv2.1 ...\nLoading ERA5-Land ...\n\n\n\n\n\n\n\n\n\nModifying the two code sections above allows the user to adjust the content of the figure.",
    "crumbs": [
      "Climate Datasets",
      "Analysis Support Tools",
      "A tool for dataset comparison: Observational Data at a point location"
    ]
  }
]